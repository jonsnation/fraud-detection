version: "3.8"

services:
  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_KRAFT_CLUSTER_ID=abcdefghijklmno
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
    volumes:
      - kafka-data:/bitnami/kafka

  transaction-producer:
    build:
      context: ./producer
    container_name: transaction-producer
    depends_on:
      - kafka
    restart: on-failure
    environment:
      - KAFKA_BROKER_URL=kafka:9092
      - PYTHONUNBUFFERED=1

  transaction-consumer:
    build:
      context: ./consumer
    container_name: transaction-consumer
    depends_on:
      - kafka
    restart: on-failure
    environment:
      - KAFKA_BROKER_URL=kafka:9092
      - PYTHONUNBUFFERED=1

  spark-master:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=master
    ports:
      - "7077:7077"
      - "8080:8080"

  spark-worker:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master

  spark-streaming-app:
    build:
      context: ./spark-app
    depends_on:
      - kafka
      - spark-master
    volumes:
      - ./jars:/opt/jars
    command: [
      "spark-submit",
      "--jars",
      "/opt/jars/spark-sql-kafka-0-10_2.12-3.4.1.jar,/opt/jars/kafka-clients-3.4.0.jar,/opt/jars/spark-token-provider-kafka-0-10_2.12-3.4.1.jar,/opt/jars/commons-pool2-2.11.1.jar",
      "/opt/spark_app.py"
    ]
   


volumes:
  kafka-data:
