{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3a93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.0-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jyc37\\anaconda3\\envs\\pt\\lib\\site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\jyc37\\anaconda3\\envs\\pt\\lib\\site-packages (from torchvision) (2.0.1)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading pillow-11.2.1-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/212.5 MB 11.2 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 6.6/212.5 MB 22.4 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 12.8/212.5 MB 26.0 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 20.4/212.5 MB 28.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 27.8/212.5 MB 29.9 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 36.7/212.5 MB 31.9 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 45.4/212.5 MB 33.5 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 54.3/212.5 MB 34.6 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 62.4/212.5 MB 35.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 70.3/212.5 MB 35.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 73.7/212.5 MB 35.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 83.4/212.5 MB 34.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 91.5/212.5 MB 35.0 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 99.6/212.5 MB 35.5 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 99.9/212.5 MB 33.0 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 100.4/212.5 MB 31.1 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 100.9/212.5 MB 29.2 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 101.4/212.5 MB 27.9 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 102.2/212.5 MB 26.3 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 103.0/212.5 MB 25.2 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 103.8/212.5 MB 24.4 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 108.8/212.5 MB 24.0 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 114.6/212.5 MB 24.1 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 121.1/212.5 MB 24.5 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 127.7/212.5 MB 24.8 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 134.5/212.5 MB 25.0 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 141.0/212.5 MB 25.3 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 148.1/212.5 MB 25.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 154.9/212.5 MB 25.8 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 162.0/212.5 MB 26.1 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 168.6/212.5 MB 26.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 175.6/212.5 MB 26.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 182.2/212.5 MB 26.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 190.3/212.5 MB 27.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 198.2/212.5 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 206.6/212.5 MB 27.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 27.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 27.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 27.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 27.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 27.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 27.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 27.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 27.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 27.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 27.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 27.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 212.5/212.5 MB 21.4 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 18.6 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.7.0-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 24.0 MB/s eta 0:00:00\n",
      "Downloading pillow-11.2.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 25.7 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.3/6.3 MB 35.1 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 31.1 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, pillow, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 pillow-11.2.1 sympy-1.14.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0 typing-extensions-4.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d688a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.7.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13035cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data   \n",
    "import pandas as pd\n",
    "import random\n",
    "from itertools import combinations, islice\n",
    "\n",
    "def create_edges(feature_column, df, max_edges_per_group=100):\n",
    "    edge_list = []\n",
    "    groups = df.groupby(feature_column).indices\n",
    "    for _, indices in groups.items():\n",
    "        n = len(indices)   \n",
    "        if n < 2:\n",
    "            continue\n",
    "        \n",
    "        pair_generator = combinations(indices, 2)\n",
    "        limited_pairs = list(islice(pair_generator, max_edges_per_group))\n",
    "        edge_list.extend(limited_pairs)\n",
    "\n",
    "    if not edge_list:\n",
    "        return torch.empty((2, 0), dtype=torch.int32)\n",
    "    return torch.tensor(edge_list, dtype=torch.int32).t().contiguous()\n",
    "\n",
    "\n",
    "X = pd.read_csv(\"reduced_features.csv\") \n",
    "y = pd.read_csv(\"balanced_labels.csv\").values\n",
    "\n",
    "#create edges for relational features\n",
    "edge_index = torch.empty((2, 0), dtype=torch.int32)\n",
    "edge_features = ['card1', 'addr1', 'addr2', 'P_emaildomain', 'DeviceType', 'id_17', 'id_28']\n",
    "for feature in edge_features:\n",
    "    edges = create_edges(feature, X, max_edges_per_group=100)\n",
    "    edge_index = torch.cat([edge_index, edges], dim=1)\n",
    "\n",
    "x_node = X.drop(columns= edge_features)\n",
    "\n",
    "data = Data(\n",
    "    x = torch.tensor(x_node.values,\n",
    "                    dtype=torch.float32),\n",
    "                    edge_index = edge_index,\n",
    "                    y = torch.tensor(y, dtype=torch.float32)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2685501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "#from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "#transform = RandomNodeSplit(split=\"train_rest\", num_val=0.15, num_test=0.15)\n",
    "#data = transform(data)\n",
    "\n",
    "class FraudGNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, 64)\n",
    "        self.conv2 = GCNConv(64, 32)\n",
    "        self.classifier = torch.nn.Linear(32, 1)\n",
    "            \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        return torch.sigmoid(self.classifier(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa257f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "\n",
    "class FraudGraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(input_dim, 64)\n",
    "        self.conv2 = SAGEConv(64, 32)\n",
    "        self.classifier = torch.nn.Linear(32, 1)\n",
    "            \n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index.to(torch.long)\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        return torch.sigmoid(self.classifier(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9530c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class FraudGraphGAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(input_dim, 32, heads=1)\n",
    "        self.conv2 = GATConv(32, 32, heads=1, concat=False)\n",
    "        self.classifier = torch.nn.Linear(32, 1)\n",
    "            \n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index.to(torch.long)\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        return torch.sigmoid(self.classifier(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213b2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def cross_validate(model_class, data, save_path, num_folds=5, num_epochs=200, lr=0.001, \n",
    "                    device=None, verbose=True):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    best_model_state = None\n",
    "    best_model = None\n",
    "    best_metric = float('-inf')\n",
    "\n",
    "\n",
    "    node_indices = torch.arange(data.num_nodes)\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(node_indices)):\n",
    "        if verbose:\n",
    "            print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "\n",
    "        train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "        train_mask[train_idx] = True\n",
    "        val_mask[val_idx] = True\n",
    "\n",
    "   \n",
    "\n",
    "        model = model_class(input_dim=data.num_node_features).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.to(device))\n",
    "            loss = loss_fn(out[train_mask], data.y[train_mask].to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            logits = model(data).squeeze()\n",
    "            probs = logits[val_mask].cpu().numpy()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "            labels = data.y[val_mask].cpu().numpy().flatten()\n",
    "\n",
    "            accuracy = (preds == labels).sum() / len(preds)\n",
    "            precision = precision_score(labels, preds, zero_division=0)\n",
    "            recall = recall_score(labels, preds, zero_division=0)\n",
    "            f1 = f1_score(labels, preds, zero_division=0)\n",
    "            roc_auc = roc_auc_score(labels, probs)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "            print(f\"Precision: {precision}\")\n",
    "            print(f\"Recall: {recall}\")\n",
    "            print(f\"f1: {f1}\")\n",
    "            print((f\"ROC-AUC Score: {roc_auc}\"))\n",
    "\n",
    "        results.append({\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'roc_auc': roc_auc\n",
    "        })\n",
    "\n",
    "        if accuracy > best_metric:\n",
    "            best_metric = accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "            best_model = model\n",
    "\n",
    "        if best_model_state is not None:\n",
    "            torch.save(best_model_state, f\"{save_path}.pt\" )\n",
    "            with open(f\"{save_path}.pkl\", \"wb\") as f:\n",
    "                pickle.dump(best_model, f)\n",
    "\n",
    "\n",
    "        metrics = {}\n",
    "        for key in results[0].keys():\n",
    "            values = [fold[key] for fold in results]\n",
    "            metrics[f\"mean_{key}\"] = sum(values) / num_folds\n",
    "            metrics[f\"std_{key}\"] = (sum((x - metrics[f\"mean_{key}\"])**2 for x in values) / num_folds) ** 0.5\n",
    "   \n",
    "\n",
    "   \n",
    "\n",
    "    return metrics, results\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1cc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNC Graph:\n",
      "Fold 1/5\n",
      "Accuracy: 0.9823076011949936\n",
      "Precision: 0.9992646124235106\n",
      "Recall: 0.9653385021531877\n",
      "f1: 0.9820086276504151\n",
      "ROC-AUC Score: 0.986480117980127\n",
      "Fold 2/5\n",
      "Accuracy: 0.9828559646590714\n",
      "Precision: 0.9992461604134311\n",
      "Recall: 0.9664016865035794\n",
      "f1: 0.9825495204243843\n",
      "ROC-AUC Score: 0.9859743962401298\n",
      "Fold 3/5\n",
      "Accuracy: 0.9827594526893938\n",
      "Precision: 0.9992193315299287\n",
      "Recall: 0.9662570224719101\n",
      "f1: 0.9824617773850643\n",
      "ROC-AUC Score: 0.9866839618411103\n",
      "Fold 4/5\n",
      "Accuracy: 0.9823777917183956\n",
      "Precision: 0.9987860449525742\n",
      "Recall: 0.9659779903970841\n",
      "f1: 0.9821080996815358\n",
      "ROC-AUC Score: 0.9875337678350189\n",
      "Fold 5/5\n",
      "Accuracy: 0.9831761351173502\n",
      "Precision: 0.9988765673697181\n",
      "Recall: 0.9674367996630485\n",
      "f1: 0.9829053352292736\n",
      "ROC-AUC Score: 0.9877217140024369\n",
      "GNC Metrics : {'mean_accuracy': np.float64(0.9826953890758409), 'std_accuracy': np.float64(0.0003200790349043443), 'mean_precision': 0.9990785433378326, 'std_precision': 0.0002043957439799105, 'mean_recall': 0.966282400237762, 'std_recall': 0.0006828060079522821, 'mean_f1': 0.9824066720741346, 'std_f1': 0.00032239479699004914, 'mean_roc_auc': np.float64(0.9868787915797647), 'std_roc_auc': np.float64(0.0006564057132682298)}\n"
     ]
    }
   ],
   "source": [
    "print(\"GNC Graph:\")\n",
    "metrics, results = cross_validate(FraudGNN, data, \"fraudgnn\")\n",
    "print(\"GNC Metrics :\", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3730b3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE Graph:\n",
      "Fold 1/5\n",
      "Accuracy: 0.9830182802444385\n",
      "Precision: 0.9985876984917345\n",
      "Recall: 0.9674171395493655\n",
      "f1: 0.9827553179641385\n",
      "ROC-AUC Score: 0.9892273796980696\n",
      "Fold 2/5\n",
      "Accuracy: 0.9831762089220929\n",
      "Precision: 0.9991288724342571\n",
      "Recall: 0.9671570995651982\n",
      "f1: 0.9828830557874018\n",
      "ROC-AUC Score: 0.9883814822304935\n",
      "Fold 3/5\n",
      "Accuracy: 0.9837026378476076\n",
      "Precision: 0.9978946607512357\n",
      "Recall: 0.9694346910112359\n",
      "f1: 0.9834588207007404\n",
      "ROC-AUC Score: 0.9901982051296863\n",
      "Fold 4/5\n",
      "Accuracy: 0.9828998337361977\n",
      "Precision: 0.9992481884057971\n",
      "Recall: 0.9665737917499037\n",
      "f1: 0.9826394456024086\n",
      "ROC-AUC Score: 0.9892649039527983\n",
      "Fold 5/5\n",
      "Accuracy: 0.9831980697521386\n",
      "Precision: 0.9991660396856332\n",
      "Recall: 0.9671998806630222\n",
      "f1: 0.9829231317995363\n",
      "ROC-AUC Score: 0.9885163192169273\n",
      "GraphSAGE Metrics : {'mean_accuracy': np.float64(0.9831990061004952), 'std_accuracy': np.float64(0.000274347029653176), 'mean_precision': 0.9988050919537315, 'std_precision': 0.0005113895623425551, 'mean_recall': 0.9675565205077451, 'std_recall': 0.0009797383703233583, 'mean_f1': 0.982931954370845, 'std_f1': 0.0002817157569576482, 'mean_roc_auc': np.float64(0.9891176580455949), 'std_roc_auc': np.float64(0.0006488243856008868)}\n"
     ]
    }
   ],
   "source": [
    "print(\"GraphSAGE Graph:\")\n",
    "gs_metrics, gs_results = cross_validate(FraudGraphSAGE, data, \"graphSage\")\n",
    "print(\"GraphSAGE Metrics :\", gs_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a34b829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT Graph:\n",
      "Fold 1/5\n",
      "Accuracy: 0.9823777917183956\n",
      "Precision: 0.9991740937721225\n",
      "Recall: 0.9655665383232325\n",
      "f1: 0.9820828817256099\n",
      "ROC-AUC Score: 0.988038819823568\n",
      "Fold 2/5\n",
      "Accuracy: 0.9829173813670482\n",
      "Precision: 0.999119342684643\n",
      "Recall: 0.966647634942246\n",
      "f1: 0.9826152953256841\n",
      "ROC-AUC Score: 0.9893222512434621\n",
      "Fold 3/5\n",
      "Accuracy: 0.9823690179029704\n",
      "Precision: 0.9987927419281636\n",
      "Recall: 0.9658883426966293\n",
      "f1: 0.9820650015395807\n",
      "ROC-AUC Score: 0.988785528289407\n",
      "Fold 4/5\n",
      "Accuracy: 0.9820882558093625\n",
      "Precision: 0.9991744609048271\n",
      "Recall: 0.9650229558756528\n",
      "f1: 0.9818018122417689\n",
      "ROC-AUC Score: 0.9869268922574223\n",
      "Fold 5/5\n",
      "Accuracy: 0.9828690502303137\n",
      "Precision: 0.9993919703789749\n",
      "Recall: 0.9663224028851469\n",
      "f1: 0.9825790189824005\n",
      "ROC-AUC Score: 0.9882977449426713\n",
      "GAT Metrics : {'mean_accuracy': np.float64(0.982524299405618), 'std_accuracy': np.float64(0.00031908538820990545), 'mean_precision': 0.9991305219337463, 'std_precision': 0.00019308274680744056, 'mean_recall': 0.9658895749445815, 'std_recall': 0.0005687491141077485, 'mean_f1': 0.9822288019630088, 'std_f1': 0.0003170087054028846, 'mean_roc_auc': np.float64(0.9882742473113062), 'std_roc_auc': np.float64(0.0008038736669739852)}\n"
     ]
    }
   ],
   "source": [
    "print(\"GAT Graph:\")\n",
    "gat_metrics, gat_results = cross_validate(FraudGraphGAT, data, \"GAT\")\n",
    "print(\"GAT Metrics :\", gat_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
