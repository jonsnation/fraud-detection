{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13035cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data   \n",
    "import pandas as pd\n",
    "import random\n",
    "from itertools import combinations, islice\n",
    "\n",
    "def create_edges(feature_column, df, max_edges_per_group=100):\n",
    "    edge_list = []\n",
    "    groups = df.groupby(feature_column).indices\n",
    "    for _, indices in groups.items():\n",
    "        n = len(indices)   \n",
    "        if n < 2:\n",
    "            continue\n",
    "        \n",
    "        pair_generator = combinations(indices, 2)\n",
    "        limited_pairs = list(islice(pair_generator, max_edges_per_group))\n",
    "        edge_list.extend(limited_pairs)\n",
    "\n",
    "    if not edge_list:\n",
    "        return torch.empty((2, 0), dtype=torch.int32)\n",
    "    return torch.tensor(edge_list, dtype=torch.int32).t().contiguous()\n",
    "\n",
    "\n",
    "X = pd.read_csv(\"reduced_features.csv\") \n",
    "y = pd.read_csv(\"balanced_labels.csv\").values\n",
    "\n",
    "#create edges for relational features\n",
    "edge_index = torch.empty((2, 0), dtype=torch.int32)\n",
    "edge_features = ['card1', 'addr1', 'addr2', 'P_emaildomain', 'DeviceType', 'id_17', 'id_28']\n",
    "for feature in edge_features:\n",
    "    edges = create_edges(feature, X, max_edges_per_group=100)\n",
    "    edge_index = torch.cat([edge_index, edges], dim=1)\n",
    "\n",
    "x_node = X.drop(columns= edge_features)\n",
    "\n",
    "data = Data(\n",
    "    x = torch.tensor(x_node.values,\n",
    "                    dtype=torch.float32),\n",
    "                    edge_index = edge_index,\n",
    "                    y = torch.tensor(y, dtype=torch.float32)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2685501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "transform = RandomNodeSplit(split=\"train_rest\", num_val=0.15, num_test=0.15)\n",
    "data = transform(data)\n",
    "\n",
    "class FraudGNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, 64)\n",
    "        self.conv2 = GCNConv(64, 32)\n",
    "        self.classifier = torch.nn.Linear(32, 1)\n",
    "            \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        return torch.sigmoid(self.classifier(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afbd3644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FraudGNN(input_dim=data.num_node_features)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #print(f\"Epoch: {epoch}, Loss: {loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf254bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9832\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds = (model(data)[data.test_mask] > 0.5).float()\n",
    "    accuracy = (test_preds == data.y[data.test_mask]).sum() / len(test_preds)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy.item():.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03925685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9995\n",
      "Recall: 0.9668\n",
      "F1-Score: 0.9829\n"
     ]
    }
   ],
   "source": [
    "# Compute TP and FP as scalars\n",
    "TP = ((test_preds == 1) & (data.y[data.test_mask] == 1)).sum().item()\n",
    "FP = ((test_preds == 1) & (data.y[data.test_mask] == 0)).sum().item()\n",
    "FN = ((test_preds == 0) & (data.y[data.test_mask] == 1)).sum().item()\n",
    "\n",
    "\n",
    "# Use .item() to convert the tensor to a scalar for the condition\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
